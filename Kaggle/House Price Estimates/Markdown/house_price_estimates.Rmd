---
title: "House Price Estimation"
author: "Aaron Webb"
date: "16/01/2020"
output: 
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Load templates
source("./www/ggplot_theme.R")
library(tidyverse)
library(caret)
library(corrplot)
```

# Introduction to the Project
## Objective of the Project

I have downloaded a dataset containing the sale price of home in an area in the US between 2006 and 2010.
Also included in the dataset are the features of each of the houses.

## Beginning the Project
To begin this project, I had a look at all of the variables contained in the data set
and mapped them based on whether they are a continious or discrete variable. 
This will aid me in two different ways.

* Firstly, when I am importing the data, I can specify which class each variable should take.
  As I am conducting regression analysis on the data, all values will need to be numeric. The dataset 
  contains categorical features, so I will therefore have to create dummy variables for these.

* Secondly, once I begin the data analysis, I can easily sort out and analyse the continious features 
  and the discrete features.

## Importing and first appearances of the data
I will start by importing the mapping table I created to identify whether a variable should be imported
as a factor or as an integer.

```{r importMappingTable, echo=T, results=F}
# Type Mapping
types_mapping <- read_csv("C:/Users/Aaron.Webb/Documents/Learning/learning_data_science/Kaggle/House Price Estimates/Inputs/identify_column_class_complete.csv")
```

Now we can use the second column in the mapping table to help with importing the data.

```{r importData}
hp_data <- read_csv("C:/Users/Aaron.Webb/Documents/Learning/learning_data_science/Kaggle/House Price Estimates/Data/train.csv", 
                    col_types = types_mapping %>%
                      pull(class_type) %>%
                      paste(collapse = ""))
head(hp_data)
```

There are 1460 instances and 80 features in the imported dataset.
As there is another separate dataset with the same features included to complete testing on, 
I am going to split the imported data into an 80/20 split of training and validation. 
This will allow me to train the model, and test it on an unknown dataset. 

```{r splitTheData}
set.seed(524)
random_rows <- floor(sample(1:nrow(hp_data), size = nrow(hp_data) * 0.8))
hp_training_data <- hp_data[random_rows, ]
hp_validation_data <- hp_data[-random_rows, ]
```

All the subsequent data analysis will be conducted on the training dataset, to minimise the chance of data leakage.

# Introduction to the Data
## The Class

The variable that I will be modelling is **SalePrice**.
This is defined as the agreed price upon the sale of the house.

```{r SalePriceSummary}
summary(hp_training_data$SalePrice)
```

As we can see in the summary above, the average sales price of a house was *$180,921*, 
while the range was between *$34,900* and *$755,00*. 
There is quite a difference between the mean and the max value in a dataset.
This can be seen a lot clearer when we look at the distibution of **SalePrice** 

```{r histogramSalePrice, warning=FALSE}
hp_training_data %>%
  select(SalePrice) %>%
  ggplot(aes(x = SalePrice)) +
  geom_histogram(bins = 100) +
  theme_custom()
```

## The Features
Now that I understand the class, lets see how the features interact with it

**TODO** I need to select some variables that I believe we have a large influence on the model.

### Visualisation



### Correlation Analysis
A simple correlation analysis will allow me to if there are any features that have 
a large influence on my class.
However, I have two issues with my training data before I can conduct the correlation analysis.

* As I have categorical values with character values in some of my features, these will need converting 
  to be numeric values. This can be completed by converting these features into dummy
  variables. This means creating a new feature for each of the unique values in the feature,
  and providing it with the value of one if that instance contains that value, while 0 if it 
  is not. I will use the function in `dummyVars` located in the `Caret` package to conduct this conversion

* There are also missing values in my dataset. In order to solve this, I will replace
  all *NAs* in the dataset with 0.
  This is a very simple way to deal with the issue of *NAs*, and can be completed in `dummyVars` too.

  
```{r correlationPrep, warning = FALSE}
dmy <- dummyVars(" ~ .",
                 data = hp_training_data,
                 sep = "_",
                 na_action = 0)

hp_training_data_dummys <- data.frame(predict(dmy,
                                              newdata = hp_training_data)) %>%
  as_tibble()
```

Now we can conduct the correlation analysis.

```{r correlationAnalysis}
#correlation_outputs <- cor(hp_training_data_dummys)
#knitr::kable(correlation_outputs)
```

We can put this into a heat map, as display a table containing all the values in would be too much information

```{r correlationHeatMap}
#corrplot(correlation_outputs)
```




### PCA 

### Feature Importance 
Hashing Encoding