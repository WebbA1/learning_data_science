---
title: "House Price Estimation"
author: "Aaron Webb"
date: "16/01/2020"
output: 
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Load templates
source("./www/ggplot_theme.R")
library(tidyverse)
library(caret)
library(knitr)
library(kableExtra)

# Chunk settings
echo_code = T
```

# Introduction to the Project
## Objective of the Project

I have downloaded a dataset containing the sale price of home in an area in the US between 2006 and 2010.
Also, included in the dataset are the features of each of the houses.

## Beginning the Project
To begin this project, I had a look at all of the variables contained in the data set
and mapped them based on whether they are a continious or discrete variable. 
This will aid me in two different ways.

* Firstly, when I am importing the data, I can specify which class each variable should take.
  As I am conducting regression analysis on the data, all values will need to be numeric. The dataset 
  contains categorical features, so I will therefore have to create dummy variables for these.

* Secondly, once I begin the data analysis, I can easily sort out and analyse the continious features 
  and the discrete features.

## Importing and First Appearances
To start off with I need data, so lets import the dataset and take a look at whats inside. 

```{r importData, echo = echo_code, warning=F, message=F}
hp_data <- read_csv("../Data/train.csv")

# Present as an output
kable(head(hp_data)) %>%
  kable_styling() %>%
  scroll_box(width = "100%")
```

There are 1460 instances,, and 80 features in the imported dataset.
As there is another separate dataset with the same features included to complete testing on, 
I am going to split the imported data into an 80/20 split of training and validation. 
This will allow me to train the model, and test it on an unknown dataset. 

```{r splitTheData, echo = echo_code}
set.seed(524)

# Select random rows for the validation dataset
random_rows <- floor(sample(1:nrow(hp_data), size = nrow(hp_data) * 0.8))

# Split into training and validation datasets
hp_training_data <- hp_data[random_rows, ]
hp_validation_data <- hp_data[-random_rows, ]
```

All the subsequent data analysis will be conducted on the training dataset, to minimise the chance of data leakage.

# Introduction to the Data
## Cleaning the Data

I need to clean the dataset before I begin attempting some simple analysis, modelling, and visualisation.
There are several issues with the data: 

* Firstly, there are a significant amount of missing thats that need resolves before modelling.
* Secondly, there are some categorical features that need to be changed to a numeric value in order for me to be able to use them in the model.



## Missing Instances {.tabset}
Lets begin by looking at the missing instances in the dataset.
I can obtain a list of the features that have missing instances, and how many they are missing too.

```{r missingDataCount, warning=F, echo = echo_code}
hp_training_data %>%
  gather("key", "value", -Id) %>%
  filter(is.na(value)) %>%
  group_by(key) %>% 
  tally() %>%
  kable() %>%
  kable_styling()
```

Now I know which features are missing instances, I can go through each one and look at a solutions I can apply.

### Alley
The **Alley** feature has 1099 missing instances, 33 Pave, and 36 Grvl.

```{r missingAlley, warning=F, echo = echo_code}
# TODO Put into kable object, create kable functions for this.
hp_training_data %>%
  group_by(Alley) %>%
  tally() %>%
  kable() %>%
  kable_styling()
```

As **Alley** as only two distinct instances, which do not have any ordering and are therefore not an ordinal sequence. 
The best way to deal with **Alley** will be to convert it into a dummy variable. 
This will involve creating two features from the original.
One will when the instance has Pave, and the other will be when the instance has Grvl. 
All the NAs will result in being 0 due to this method. We will be assuming there are only two options, as thats what the data tells us.

### Bsmt

I've grouped all the **Bsmt** features into one, so they can be analysed for NAs altogether.
Lets look at how many missing instances there are for each **Bsmt** feature.

```{r missingBsmt, warning= F, echo=echo_code}
hp_training_data %>%
  select(starts_with("Bsmt")) %>%
  gather("key", "value") %>%
  group_by(key, value) %>%
  tally() %>%
  filter(is.na(value)) %>%
  kable() %>%
  kable_styling()
```


From the table above, I've noticed that two features have an extra NA instance, 
**BsmtExposure** and **BsmtFinType2**. Lets have a look and see where they appear in the data.

```{r BsmtIdCheck, warning=F, echo=echo_code}
hp_training_data %>%
  select(Id, starts_with("Bsmt")) %>%
  gather("key", "value", -1) %>%
  filter(is.na(value)) %>%
  group_by(Id) %>%
  tally() %>%
  kable() %>%
  kable_styling() %>%
  scroll_box(width = "100%", height = "300px")
```

Now I know which Ids contain the NAs, i can filter my dataset by these Ids and see why 
**BsmtExposure** and **BsmtFinType2** have an extra NA.

```{r BsmtAllNAs, warning=F, echo=echo_code}
BsmtIdNAs <- hp_training_data %>%
  select(Id, starts_with("Bsmt")) %>%
  gather("key", "value", -1) %>%
  filter(is.na(value)) %>%
  distinct(Id) %>%
  pull(Id)
# TODO Highlight the NAs in the table.
hp_training_data %>%
  select(Id, starts_with("Bsmt")) %>%
  filter(Id %in% BsmtIdNAs) %>%
  arrange(Id) %>%
  kable() %>%
  kable_styling() %>%
  scroll_box(width = "100%", height = "300px")
```

The extra NA for **BsmtExposure** is at Id 949. Looking at the other basement features, 
I can see that there is clearly a basement being built/renovated, as **BsmtFinType1** is saying its unfinished.
This leads me to believe the data collector was unsure about what exposure the basement would have. 
Therefore, it is difficult to decide what to do to this instance. 
Do we remove it as we are unsure about the data, or do we apply zero?

For now, I will apply the value of 0.

As for extra NA in **BsmtFinType2**, this appears in Id 333. As **BsmtFinType1** has a value, 
and there is a value in **BsmtFinSF2**, I will assume that the second room is unfinished.

For all of the Bsmt variables, I can apply an ordinal value to the characters. 
If the data is NA, I will apply the value of zero under the assumption that the property is missing a basemen due to **BsmtFinSF** is 0.

### Electrical

### Fence

### FireplaceQu

### Garage

### LotFrontage

### MasVnr

### MiscFeature

### PoolQC



